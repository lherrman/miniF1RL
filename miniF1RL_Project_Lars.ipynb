{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# TuIT_DeepRL - DRL Project\n",
    "![OST](./resources/ost_logo.png)\n",
    "## MiniF1RL: My pygame 2d racing environment for DRL\n",
    "Author: Lars Herrmann    \n",
    "Date: 12.04.2024  \n",
    "Repository: [Github - miniF1RL](https://github.com/lherrman/miniF1RL)   \n",
    "Python Version: 3.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "After a lot of experimentaition and consideration of what environment to use. (Playing with e.g. TrackManiaRL, Gymnasium Integrated Environemnts and Unity Environments), i decided to implement my own 2d racing environment. The main reason for this is that i wanted a environment where no pre-trained models are available what motivates me to train my own models. As i started watching formula one this season, i wanted to go with a racing environment. \n",
    "\n",
    "## Implementing the environment\n",
    "\n",
    "### The CarModel\n",
    "As a starting point, i was able to use a Python class of a simple 2d topdown car model that i implemented for another project about a year ago. The class already had methods to draw a simple 2d box car and it's wheels onto a pygame screen. As it wasn't intended as a racing game, and rather a geometrical model, i had to implement an updated method for updating the cars position and velocity to make it more fun to drive. The original CarModel class can be found in my github repository for the [SlamCar Project](https://github.com/lherrman/slamcar-controller) in the file `base_model.py`.\n",
    "\n",
    "To make this into a racing environment, there were still some parts missing i startet to implement, starting with a track to drive on.\n",
    "\n",
    "### The Track\n",
    "In order to have a track to drive on, i decided to draw a black and white image of a track in photoshop. When initializing the car model, i wrote a python method that uses the 'cv2.findContours' method to find the track boundaries in the image. The track is then represented as two lists of points, one for the inner and one for the outer boundary.\n",
    "\n",
    "![Track Image](./resources/MakeTrack.png)\n",
    "\n",
    "\n",
    "Python Code:\n",
    "```python\n",
    "    def _get_track_boundaries_from_image(self, image_path) -> dict:\n",
    "        '''\n",
    "        Using opencv to read the image and find the contours of the track boundaries.\n",
    "        The boundaries are represented as list of points. ([x1, y1], [x2, y2], ...)\n",
    "        '''\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        contours, _ = cv2.findContours(image.astype('uint8'), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        assert len(contours) == 2, \"There should be exactly 2 contours in the image\"\n",
    "\n",
    "        # Transform and downsample the contours\n",
    "        downsample_rate = 10\n",
    "        inner_boundary = contours[0][:, 0, :][::downsample_rate]\n",
    "        outer_boundary = contours[1][:, 0, :][::downsample_rate]\n",
    "\n",
    "        # # Append last point to close the loop\n",
    "        inner_boundary = np.append(inner_boundary, [inner_boundary[0]], axis=0)\n",
    "        outer_boundary = np.append(outer_boundary, [outer_boundary[0]], axis=0)\n",
    "\n",
    "        # Scale the contours to make suitable for the simulation\n",
    "        inner_boundary, outer_boundary = inner_boundary / 60, outer_boundary / 60\n",
    "\n",
    "        return {\n",
    "            'inner': inner_boundary,\n",
    "            'outer': outer_boundary\n",
    "        }   \n",
    "```\n",
    "\n",
    "#### Track progress\n",
    "To approximate the progress the car has made on the track, i implemented a method `_calculate_track_progress` that calculates the distance to the next point on the inner boundary. The first point on the inner boundary is set as the starting point. The progress is then calculated as the index of the nearest point divided by the total number of points on the inner boundary. This could be improved by using the distance from the starting point to the nearest point on the inner boundary as the progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The observation space\n",
    "\n",
    "I wanted to keep the observation space simple, so i decided to use 'lidar sensors', that give the car only a few distance measurements in front of it. I decided to use 3 sensors, one in the middle and one on each side of the car in a 45 degree angle. The sensors are implemented as a method of the CarModel class that returns the distances to the track boundaries. \n",
    "\n",
    "The implementation of the `_segment_intersection` and `_raycast` methods was prompted to ChatGPT, which returned an working implementation after 2-3 iterations. The method uses an all python implementation for which the performance isn't optimal, but i guess it's good enough for my purposes. As the raycast method has to itterate over each segment of the boundaries, a more performant implementation would be beneficial.\n",
    "\n",
    "For easier validation, and because it looks cool, i decided to draw the lidar sensors as lines on the pygame screen.\n",
    "\n",
    "![Lidar Sensors](./resources/lidars.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The action space\n",
    "\n",
    "The action space is also very simple. To make the problem even easier for the RL algorithm, i decided to always have the car accelerate, as slowing down isn't necessary in this environment. The car can steer left or right, or go straight. To make it a little more interesting, i added a third action, boost, that allows the car to go faster on the straights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The reward function\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datetime import datetime\n",
    "import threading\n",
    "import torch\n",
    "import pygame\n",
    "from minif1env import MiniF1RLEnv\n",
    "from stable_baselines3 import A2C, PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def get_writer(texts: dict):\n",
    "    writer = SummaryWriter()\n",
    "    for key, value in texts.items():\n",
    "        writer.add_text(str(key), str(value))\n",
    "    return writer\n",
    "\n",
    "# Use a separate thread to render the environment\n",
    "# Avoids crashing the pygame window during training\n",
    "def render_thread(env, close_event):\n",
    "    while True:\n",
    "        env.render()\n",
    "        pygame.time.wait(10) \n",
    "        # get events for the window to stay responsive\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                close_event.set()\n",
    "                return\n",
    "        if close_event.is_set():\n",
    "            return\n",
    "\n",
    "# Create the environment\n",
    "env = MiniF1RLEnv(render_mode='no')\n",
    "model_description = \"a2c_minif1rl\"\n",
    "run_name = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") + \"_\" + model_description\n",
    "\n",
    "# Create and start the rendering thread\n",
    "close_event = threading.Event()\n",
    "render_thread = threading.Thread(target=render_thread, args=(env,close_event))\n",
    "render_thread.start()\n",
    "\n",
    "# Set the total timesteps for training\n",
    "total_timesteps = 1_000_000\n",
    "\n",
    "# Tensorboard writer\n",
    "writer = get_writer({\"run_name\": run_name,\n",
    "                    \"model_description\": model_description,\n",
    "                    \"total_timesteps\": total_timesteps,\n",
    "                    \"env_name\": \"MiniF1RLEnv\",\n",
    "                    \"reward_weights\": env.get_reward_weights()})\n",
    "\n",
    "# Define the policy network and enable GPU usage\n",
    "policy_kwargs = dict(activation_fn=torch.nn.ReLU, net_arch=[64, 64])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create the A2C model with PyTorch policy and enable GPU training\n",
    "#model = A2C(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, device=device, verbose=1)\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "# Train the model\n",
    "model.learn(total_timesteps=total_timesteps, progress_bar=False, tb_log_name=run_name)\n",
    "model.save(f\"models/{run_name}\")\n",
    "\n",
    "# Close the rendering thread and environment\n",
    "close_event.set()\n",
    "render_thread.join()\n",
    "env.close()\n",
    "\n",
    "# Close the tensorboard writer\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Log\n",
    "\n",
    "## 01\n",
    "Model: 2024-04-12_14-00-00  \n",
    "Timesteps: 10'000   \n",
    "Training Time: 1h 10min  \n",
    "Result: The car learned to always directly drive into the right border.   \n",
    "Explaination. After checking the rewards that were given to the model, i realized that the reward function was not working as intended. The weight for the progress reward was way to low so the model did not learn to follow the track. Probebly also the punishment for hitting the track boundaries was to low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
